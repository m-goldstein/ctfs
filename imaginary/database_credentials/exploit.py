import requests
import json
import time
import base64 as b64
import re
host = 'https://api.github.com/repos/Et3rnos/ImaginaryCTF'
pat = {'Authorization':'token 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'}
parse = lambda x,y: [e[y] for e in x]
regex = re.compile(r'user=ictf\w+')
matches = []

def get(host):
    global regex,matches
    try:
        r = requests.get(host,headers=pat)
        data = r.json()
        matches += [r.text[e.start():e.start()+100] for e in regex.finditer(r.text)]
        return data
    except Exception as e:
        print(f'[get] Exception: {e}')

def preprocess(host=host,endpoint=''):
    try:
        if (host+endpoint).endswith('/events'):
            tmp = get(host+endpoint)
            #print(f'[preprocess] got {tmp=}')
            data = [e for e in tmp if e['type'] in ['PushEvent','MergeEvent']]
            return data
        else:
            return get(host+endpoint)
    except Exception as e:
        print(f'[preprocess] Exception: {e}')

def gen_commit_hrefs(host=host,events=[],commit_hrefs=[]):
    events += preprocess(host,endpoint='/events')
    for e in events:
        commits = e['payload']['commits']
        parent = e['payload']['before']
        if f'{host}/commits/{parent}' not in commit_hrefs:
            commit_hrefs += [f'{host}/commits/{parent}']
        for c in commits:
            if c['url'] not in commit_hrefs:
                commit_hrefs += [c['url']]
    return list(events),list(commit_hrefs)

def process_commit(commit='',trees=[],patches=[]):
    stack = []
    try:
        data = get(commit)
        if 'comments_url' in data:
            comments = get(data['comments_url'])
        parents = [e['url'] for e in data['parents']]
        tree = data['commit']['tree']['url']
        if tree not in trees:
            trees += [tree]
        for e in data['files']:
            if 'patch' in e.keys():
                patch = (e['sha'],e['patch'])
            elif 'contents_url' in e.keys():
                patch = (e['sha'],e['contents_url'])
            
            if patch[0] not in parse(patches,0):
                patches += [patch]
    except Exception as e:
        print(f'[process_commit] Exception: {e}')
    return list(trees),list(patches),list(parents)

def gen_trees(commits=[],trees=[],patches=[]):
    for commit in commits:
        t,p,prev = process_commit(commit=commit)
        for e in prev:
            if e not in commits:
                commits += [e]
        for e in t:
            if e not in trees:
                trees += [e]
        for e in p:
            if e[0] not in parse(patches,0):
                patches += [e]
        print(f'processed {commit=}')
    return list(trees),list(patches)

def process_tree(tree='',blobs=[]):
    stack = []
    try:
        data = get(tree)
        t = [e for e in data['tree']]
        for e in t:
            sha = e['sha']
            fname = e['path']
            url = e['url']
            blob = (sha,fname,url)
            if e['type'] == 'blob':
                if blob[0] not in parse(blobs,0):
                    blobs += [blob]
            elif e['type'] == 'tree' and e['url'] not in stack:
                stack.append(e['url'])
    except Exception as e:
        print(f'[process_tree] Exception: {e}')
        print(f'[process_tree] {data=}')
    return list(blobs),list(stack)
def process_metadata(trees=[], queries=[]):
    seen = []
    for tree in trees:
        try:
            blob,refs = process_tree(tree=tree)
            for e in refs:
                if e not in trees:
                    trees += [e]
            urls = parse(blob,2)
            for e in urls:
                if e in seen:
                    continue
                data = get(e)
                sha = data['sha']
                payload = data['content']
                decoded = b64.b64decode(payload)
                entry = (sha,decoded)
                print(f'entry: {sha=}')
                if entry[1] not in parse(blobs,1):
                    blobs += [entry]
                print(f'processed blob url: blobs/{e.rsplit("/")[-1]}')
                seen.append(e)
        except Exception as e:
            print(f'[process_blobs] Exception: {e}')
        print(f'processed tree url: trees/{tree.rsplit("/")[-1]}')
    return list(blobs)
"""
def process_blobs(trees=[], blobs=[]):
    seen = []
    for tree in trees:
        try:
            blob,refs = process_tree(tree=tree)
            for e in refs:
                if e not in trees:
                    trees += [e]
            urls = parse(blob,2)
            for e in urls:
                if e in seen:
                    continue
                data = get(e)
                sha = data['sha']
                payload = data['content']
                decoded = b64.b64decode(payload)
                entry = (sha,decoded)
                print(f'entry: {sha=}')
                if entry[1] not in parse(blobs,1):
                    blobs += [entry]
                print(f'processed blob url: blobs/{e.rsplit("/")[-1]}')
                seen.append(e)
        except Exception as e:
            print(f'[process_blobs] Exception: {e}')
        print(f'processed tree url: trees/{tree.rsplit("/")[-1]}')
    return list(blobs)
"""

events,commits = gen_commit_hrefs()

print(f'generated list of {len(commits)} commits')

trees,patches = gen_trees(commits=commits)
patch_bodies = parse(patches,1)
print(f'generated list of {len(trees)} trees')
#blobs = process_blobs(trees=trees)
#print(f'generated list of {len(blobs)} blobs')
